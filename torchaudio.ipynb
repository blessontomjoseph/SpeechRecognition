{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "from typing import Union,List,Optional,Dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_data=torchaudio.datasets.LIBRISPEECH('./',url='dev-clean',download=True)\n",
    "val_data=torchaudio.datasets.LIBRISPEECH('./',url='test-clean',download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] the data format is *tuple(waveform:torch.Tensor, _ , _ , _ , _ ,_)*\n",
    "- [x] so we take thewave form only and process it.but, the shape is (1,x) x is diffrent for diff waveforms x is in lacks\n",
    "- [x] once processed the waveform becomes of the shape - (1,128,x) here x is <1000 but different for each single data\n",
    "- [x] we wanna batch the data with a unique size\n",
    "- [x] in the function __getitem__(self idx) idx is a number and taking self.data[idx] takes one element so the entire function should be written for procesing a single data point the batch ing of these points are somehow done by the ***torch.utils.data.DataLoader*** function you dont have tyo worry about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    max_length=124 #totally randomly picked change accordingly\n",
    "    train_batch_size=16\n",
    "    val_batch_size=8\n",
    "    padding_value=0\n",
    "    tokenizer_checkpoint='bert-base-cased'\n",
    "    cnn_layers=3\n",
    "    rnn_layers=5\n",
    "    input_features=128\n",
    "\n",
    "\n",
    "train_transforms=nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    ")\n",
    "# after the transformation what we get is (batch ,channel,feature,time)\n",
    "val_transforms=nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram()\n",
    ")\n",
    "\n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self,data_url:str,tokenizer:transformers.AutoTokenizer,transforms:nn.Sequential,mode=Union['train','val'])->Dict['inputs','targets']:\n",
    "        self.tokenizer=tokenizer\n",
    "        self.mode=mode\n",
    "        if mode=='train':\n",
    "            self.data=data_url\n",
    "            # self.data= torchaudio.datasets.LIBRISPEECH('./',url=train_url,download=True)\n",
    "            self.transforms=transforms\n",
    "        if mode =='val':\n",
    "            self.data=data_url\n",
    "            # self.data= torchaudio.datasets.LIBRISPEECH('/',url=val_url,download=True)\n",
    "            self.transforms=transforms\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        single_audio,transcript=self.transforms(self.data[idx][0]),self.data[idx][2]\n",
    "        label=self.tokenizer.encode(transcript,truncation=True,padding='max_length',max_length=30,return_tensors='pt') #bert_tokenizer.decode(token.squeeze(0),skip_special_tokens=True):'to decode'\n",
    "        \n",
    "        if single_audio.shape[2]>Config.max_length:\n",
    "            single_audio=single_audio[:,:,:Config.max_length]\n",
    "        else:\n",
    "            left=Config.max_length-single_audio.shape[2]\n",
    "            single_audio=torch.cat([single_audio,torch.zeros(1,128,left)],dim=2)\n",
    "    \n",
    "        return {\n",
    "                self.mode:single_audio,\n",
    "                'label':label.squeeze_(0)\n",
    "                }\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "bert_tokenizer=AutoTokenizer.from_pretrained(Config.tokenizer_checkpoint)   \n",
    "    \n",
    "Train_Loader=DataLoader(Dataloader(train_data,tokenizer=bert_tokenizer,transforms=train_transforms,mode='train'),batch_size=Config.train_batch_size,shuffle=True)\n",
    "Val_Loader=DataLoader(Dataloader(val_data,tokenizer=bert_tokenizer,transforms=train_transforms,mode='val'),batch_size=Config.val_batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128, 124])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(Train_Loader))['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layernorm(x,n_feat):\n",
    "    layer=nn.LayerNorm(n_feat)\n",
    "    return layer(x)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel,stride,padding,dropout_probability,input_features):\n",
    "        super().__init__()\n",
    "        self.input_features=input_features\n",
    "        self.conv_1=nn.Conv2d(in_channels,out_channels,kernel,stride,padding)\n",
    "        self.conv_2=nn.Conv2d(out_channels,out_channels,kernel,stride,padding)  #if not necesseary change out_ch,out_ch\n",
    "        self.drop_1=nn.Dropout(dropout_probability)\n",
    "        self.drop_2=nn.Dropout(dropout_probability)\n",
    "    \n",
    "    def forward(self,batch):\n",
    "        residue=batch\n",
    "        batch=f.gelu(layernorm(batch,self.input_features))\n",
    "        batch=self.drop_1(batch)\n",
    "        batch=self.conv_1(batch)\n",
    "        batch=f.gelu(layernorm(batch,self.input_features))\n",
    "        batch=self.drop_2(batch)\n",
    "        batch=self.conv_2(batch)\n",
    "        return batch+residue\n",
    "    \n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers,dropout_probability):\n",
    "        \"\"\"\n",
    "        input_size=n_features\n",
    "        hidden_size= nom feature in the hidden state\n",
    "        num_layers= how many rnns do you wanna stack\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bi_gru=nn.GRU(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,batch_first=True,bidirectional=True)\n",
    "        self.drop=nn.Dropout(dropout_probability)\n",
    "        \n",
    "    def forward(self,batch):\n",
    "        batch=f.gelu(layernorm(batch))\n",
    "        batch=self.bi_gru(batch)\n",
    "        batch=self.drop(batch)\n",
    "        return batch\n",
    "    \n",
    "    \n",
    "class Config_cnn:\n",
    "    input_channels=32\n",
    "    output_cahnnels=32\n",
    "    kernel_size=3\n",
    "    stride=1    \n",
    "    padding=1\n",
    "    dropout_probability=0.1\n",
    "    input_features=128\n",
    "\n",
    "class Config_rnn:\n",
    "    input_size=512 # must be the n_features of the input (input_size abd hidden size same for first bi_rnn lets say x) then for evey next layer input_size=2x and hidden_size=x\n",
    "    hidden_size=512\n",
    "    num_layers=1\n",
    "    dropout_probability=0.1\n",
    "    \n",
    "class Config_classifier:\n",
    "    cnn_layers=3\n",
    "    rnn_layers=5\n",
    "    input_size=Config_rnn.input_size\n",
    "    dropout_probability=0.1\n",
    "    num_classes=29 #for some reason\n",
    "\n",
    "\n",
    "    \n",
    "class audio(nn.Module):\n",
    "    def __init__(self,cnn_layers,rnn_layers,input_features,max_length,batch_size,out_channels):\n",
    "        super().__init__()\n",
    "        self.input_features=input_features\n",
    "        self.max_length=max_length\n",
    "        self.batch_size=batch_size\n",
    "        self.out_channels=out_channels\n",
    "        \n",
    "        self.cnn=nn.Conv2d(input_channels=1,\n",
    "                            output_channels=32,\n",
    "                            kernel_size=3,\n",
    "                            stride=2,\n",
    "                            padding=1)\n",
    "        \n",
    "        self.linear=nn.Linear(32*self.input_features,Config_rnn.input_size)  #lil issue contradicts with my reference\n",
    "        \n",
    "        self.res_cnn=nn.Sequential(*[ResidualCNN(input_channels=Config_cnn.input_channels,\n",
    "                                                 output_channels=Config_cnn.output_cahnnels,\n",
    "                                                 kernel_size=Config_cnn.kernel_size,\n",
    "                                                 stride=Config_cnn.stride,\n",
    "                                                 padding=Config_cnn.padding,\n",
    "                                                 dropout_probability=Config_cnn.dropout_probability) for _ in range(cnn_layers)])\n",
    "        \n",
    "        self.rnn_layers=nn.Sequential(*[BidirectionalGRU(input_size=Config_rnn.input_size if i==0 else 2*Config_rnn.input_size,\n",
    "                                                         hidden_size=Config_rnn.hidden_size,\n",
    "                                                         num_layers=Config_rnn.num_layers,\n",
    "                                                         drop_p=Config_rnn.dropout_probability) for i in range(rnn_layers)])\n",
    "        self.classifier=nn.Sequential(\n",
    "                                    nn.Linear(Config_classifier.input_size*2,Config_classifier.input_size),\n",
    "                                    nn.GELU(),\n",
    "                                    nn.Dropout(Config_classifier.dropout_probability),\n",
    "                                    nn.Linear(Config_classifier.input_size,Config_classifier.num_classes)\n",
    "                                    )\n",
    "        \n",
    "    def forward(self,batch):\n",
    "        out=self.cnn(batch)\n",
    "        out=self.res_cnn(out)\n",
    "        out.view(self.batch_size,self.max_length,self.out_channels*self.input_features) #batch,features:32*128, the other dimension this can potentially load into nn.linear \n",
    "        out=self.linear(out)\n",
    "        out=self.rnn_layers(out)\n",
    "        out=self.classifier(batch)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cnn=ResidualCNN(Config_cnn.input_channels,\n",
    "                      Config_cnn.output_cahnnels,\n",
    "                      kernel=Config_cnn.kernel_size,\n",
    "                      stride=Config_cnn.stride,\n",
    "                      padding=Config_cnn.padding,\n",
    "                      dropout_probability=Config_cnn.dropout_probability,\n",
    "                      input_features=Config_cnn.input_features)\n",
    "\n",
    "# dummy_cnn2=nn.Sequential(*[dummy_cnn for i in range(3)])\n",
    "\n",
    "# gru=BidirectionalGRU(\n",
    "#     input_size=Config_rnn.input_size,\n",
    "#     hidden_size=Config_rnn.hidden_size,\n",
    "#     num_layers=Config_rnn.hidden_size,\n",
    "#     dropout_probability=Config_rnn.dropout_probabilitys\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) for _ in range(n_cnn_layers)])\n",
    "        \n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        \n",
    "        self.birnn_layers = nn.Sequential(*[BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)for i in range(n_rnn_layers)])\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "                                        nn.GELU(),\n",
    "                                        nn.Dropout(dropout),\n",
    "                                        nn.Linear(rnn_dim, n_class))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*['a' for i in range(3)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
